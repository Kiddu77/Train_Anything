{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the data as categories on a csv file\n",
    "For this notebook we are gonna take the Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('datasets/train.csv'))\n",
    "data = torch.tensor(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part decides the category that is the output and the rest are taken as input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:,0]\n",
    "x = data[:,1:]/255   # pixel values reduced to range 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = x[:int(0.8*len(x))]\n",
    "ytrain = y[:int(0.8*len(y))]\n",
    "xval = x[int(0.8*len(x)):int(0.9*len(x))]\n",
    "yval = y[int(0.8*len(y)):int(0.9*len(y))]\n",
    "xest = x[int(0.9*len(x)):]\n",
    "yest = y[int(0.9*len(y)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the categories listed below with the number of training examles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33600, 784]), torch.Size([33600]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_sz = 4   # batch size\n",
    "n_fl = 128   # number of neurons in the first layer\n",
    "n_ml = 64    # number of neurons in the middle layer\n",
    "n_ol = 10    # number of neurons in the output layer (Number of possible outcomes depicted as a neuron each)\n",
    "ex_len = 784 # context length of one example\n",
    "epoch = 10   # number of iterations on the entire dataset\n",
    "l_r = 0.001  # learning rate\n",
    "nl_r =0.0001 #rectified finetune stage learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is the representation of fully connected deep neural network with the output neuron activations as the probability of the possible outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(ex_len,n_fl),\n",
    "    #nn.ReLU(),\n",
    "    nn.Tanh(),\n",
    "    #nn.Sigmoid(),\n",
    "    nn.Linear(n_fl,n_ml), \n",
    "    #nn.ReLU(),\n",
    "    #nn.Tanh(),\n",
    "    #nn.Sigmoid(),\n",
    "    #nn.Dropout(0.0),\n",
    "    nn.Linear(n_ml,n_ol),   # this layer will output the activations of 10 neurons (probability of the outputs)\n",
    "    #nn.ReLU(),\n",
    "    #nn.Tanh(),\n",
    "    #nn.Sigmoid(),\n",
    "    #nn.Softmax(),\n",
    ")\n",
    "\n",
    "ix = (torch.randperm(len(xtrain)-bat_sz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the optimiser for the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=l_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():    # Accuracy calculation function (on validation data)\n",
    "    k,d=len(xval),len(xval)\n",
    "    for n in range(len(xval)):\n",
    "        omt = ((model(xval[n]))).tolist()\n",
    "        k -= (omt.index(max(omt))==yval[n].item())\n",
    "    accu = (((d-k)/d) *100)\n",
    "    return(\"Accuracy = \" + str(accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iterator iterates throught all the randomised training examples and calculates the accuracy every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10, Accuracy = 90.71428571428571\n",
      "2 / 10, Accuracy = 92.38095238095238\n",
      "3 / 10, Accuracy = 93.33333333333333\n",
      "4 / 10, Accuracy = 94.0952380952381\n",
      "5 / 10, Accuracy = 94.76190476190476\n",
      "6 / 10, Accuracy = 95.21428571428572\n",
      "7 / 10, Accuracy = 95.83333333333334\n",
      "8 / 10, Accuracy = 96.16666666666667\n",
      "9 / 10, Accuracy = 96.42857142857143\n",
      "10 / 10, Accuracy = 96.33333333333334\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    for i in ix:\n",
    "        xt = xtrain[i:i+bat_sz]    # selecting the batch \n",
    "        yt = ytrain[i:i+bat_sz]     \n",
    "        X_train = xt.view([bat_sz,ex_len])   # creating the appropriate tensor size\n",
    "        Y_train = F.one_hot(yt,n_ol).float()   # creating a one hot vector representation of the possible output\n",
    "\n",
    "        t = model(X_train.float())\n",
    "        loss = F.cross_entropy(t,Y_train)    # Loss definition\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "        loss.backward()     # accumulating the gradient\n",
    "        optimizer.step()    # rectifying the weights using the gradients\n",
    "        \n",
    "        # print(loss.item())\n",
    "        \n",
    "    print(str(e+1) + \" / \" + str(epoch)+\", \" + accuracy())\n",
    "    if(e == int(0.8*epoch)):\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=nl_r)  # decreasing the learning rate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs really good on categorization datasets where you have a certain classes and you need to predict a class.\n",
    "You can go ahead and run almost anything on it and get a decent accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
